{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "505cf4b7",
   "metadata": {},
   "source": [
    "# Visualize best saved results of run.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43597d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports.\n",
    "import sys, os\n",
    "sys.path.append('../../')\n",
    "\n",
    "from flex.tools.utils import get_ground, rotmat2aa\n",
    "from psbody.mesh.colors import name_to_rgb\n",
    "from flex.tools.config import Config\n",
    "from omegaconf import OmegaConf\n",
    "from psbody.mesh import Mesh\n",
    "import meshplot as mp\n",
    "import numpy as np\n",
    "import smplx\n",
    "import torch\n",
    "import mano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d10284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions and variables.\n",
    "\n",
    "def get_sbj(cfg, res):\n",
    "    # ---- (*) BODY\n",
    "    sbj_m = smplx.create(model_path=f'../../{cfg.smplx_dir}',\n",
    "                        model_type='smplx',\n",
    "                        gender='neutral',\n",
    "                        num_pca_comps=np.array(24),\n",
    "                        batch_size=1).to('cpu').eval()\n",
    "    body_params = {'transl': torch.Tensor(res['transl'].reshape(1,3)),\n",
    "                   'global_orient': torch.Tensor(res['global_orient'].reshape(1,3)),\n",
    "                   'body_pose': torch.Tensor(res['pose'].reshape(1,63))}\n",
    "    bm = sbj_m(**body_params)\n",
    "    body_vertices = bm.vertices.detach().cpu().numpy()[0]\n",
    "    body_vertices[..., 2] -= body_vertices[..., 2].min(-1, keepdims=True)[0]\n",
    "    return body_vertices, sbj_m.faces\n",
    "\n",
    "\n",
    "def get_rh(cfg, res):\n",
    "    # ---- (*) RHAND\n",
    "    rh_m = mano.load(model_path=f'../../{cfg.mano_dir}',\n",
    "                     is_right=True,\n",
    "                     model_type='mano',\n",
    "                     gender='neutral',\n",
    "                     num_pca_comps=45,\n",
    "                     flat_hand_mean=True,\n",
    "                     batch_size=1).to('cpu').eval()\n",
    "    return res['rh_verts'].reshape(-1, 3), rh_m.faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedf4b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set example.\n",
    "obj_name, recept, ornt, index = 'stapler', 'receptacle_aabb_TvStnd1_Top3_frl_apartment_tvstand', 'all', 0\n",
    "\n",
    "# Load dataset.\n",
    "recept_dict = dict(np.load('../../data/replicagrasp/receptacles.npz', allow_pickle=1))\n",
    "dset_info_dict = dict(np.load('../../data/replicagrasp/dset_info.npz', allow_pickle=1))\n",
    "\n",
    "# Load tto optimization human result.\n",
    "res = dict(np.load(f'../../save/{obj_name}/{recept}/{ornt}_{index}.npz', allow_pickle=True))\n",
    "\n",
    "# Setup cfg.\n",
    "cfg = OmegaConf.structured(Config)\n",
    "config_yaml = OmegaConf.load('../configs/flex.yaml')\n",
    "cfg = OmegaConf.merge(cfg, config_yaml)\n",
    "cfg.obj_name = obj_name\n",
    "\n",
    "# Mesh path.\n",
    "mesh_pth = '../../data/obj/contact_meshes/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206b416f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---> Load data.\n",
    "transl_grab, orient_grab, recept_idx = dset_info_dict[f'{obj_name}_{recept}_{ornt}_{index}']\n",
    "recept_v, recept_f = recept_dict[recept][recept_idx][0], recept_dict[recept][recept_idx][1]\n",
    "\n",
    "# ---> Visualize receptacle meshes in scene.\n",
    "mp_viewer = mp.plot(recept_v, recept_f, name_to_rgb['yellow'])\n",
    "\n",
    "# ---> Visualize ground for context (center it to mean of rigid/articulated object).\n",
    "grnd_mesh = get_ground(grnd_size=10, offset=0.0)\n",
    "xmean, ymean, _ = recept_v.mean(0)\n",
    "grnd_mesh.v[:, 0] += xmean\n",
    "grnd_mesh.v[:, 1] += ymean\n",
    "mp_viewer.add_mesh(grnd_mesh.v, grnd_mesh.f, name_to_rgb['brown'])\n",
    "\n",
    "# ---> Visualize object to be grasped in scene.\n",
    "object_mesh = Mesh(filename=os.path.join(mesh_pth, obj_name + '.ply'), vscale=1.)\n",
    "obj_verts = np.matmul(object_mesh.v, orient_grab.T) + transl_grab\n",
    "mp_viewer.add_mesh(obj_verts, object_mesh.f, name_to_rgb['blue'])\n",
    "\n",
    "# -----------\n",
    "# Get top-5 result.\n",
    "for idx, color in enumerate(['green', 'pink', 'yellow', 'gray', 'orange']):\n",
    "    res_i = dict(res['arr_0'].item())['final_results'][idx]\n",
    "    res_i_new = res_i.copy()\n",
    "    res_i_new['global_orient'] = rotmat2aa(torch.Tensor(res_i['global_orient']).reshape(1,1,1,9)).reshape(1, 3).numpy()\n",
    "    # Visualize human.\n",
    "    sbj_v, sbj_f = get_sbj(cfg, res_i_new)\n",
    "    mp_viewer.add_mesh(sbj_v, sbj_f, name_to_rgb[color])\n",
    "    # (Optional) Uncomment below lines to visualize target rhand grasp.\n",
    "    # rh_v, rh_f = get_rh(cfg, res_i_new)\n",
    "    # mp_viewer.add_mesh(rh_v, rh_f, name_to_rgb['red'])\n",
    "\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
